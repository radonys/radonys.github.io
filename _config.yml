# Site
repository: radonys/radonys.github.io
favicon: images/favicon.ico

# Content configuration version
version: 2

# Personal info
name: Yash Srivastava
title: Data Engineer

darkmode: false

# Social links
linkedin_username: radonys
github_username:  radonys
twitter_username: yashsri97
# facebook_username: yashsrivastava30
# instagram_username: yashsrivastava7
# dribbble_username: jekyll
# flickr_username: jekyll
# pinterest_username: jekyll
# youtube_username: globalmtb
# googleplus_username: +jekyll

additional_links:
- title: Google Scholar link
  icon: fab fa-google
  url: https://scholar.google.com/citations?user=Pd4WGpUAAAAJ&hl=en
  
- title: Blogger link
  icon: fab fa-blogger
  url: http://radonys.blogspot.com/

# About Section
# about_title: About Me
about_profile_image: images/data_science_data_analyst_software_development_data_engineer.jpg
about_content: | # this will include new lines to allow paragraphs
  Hi, my name's Yash and I'm a recent graduate student from University of Maryland. Thank you for visiting my website and hit me up to discuss about recent happenings in data science and new oppurtunities. 

  I am most skilled in: <mark>Python</mark>, <mark>SQL</mark> and <mark>Machine Learning</mark>.

  You can reach out to me via [email](mailto:yash.srivastava@outlook.com).

content:
  - title: Experience
    layout: list
    content:
      - layout: left
        title: NWO.AI
        link: nwo.ai
        sub_title: Data Engineer
        caption: March 2021 - Present
        description: | # this will include new lines to allow paragraphs
          - Lead data engineering efforts and build social, financial, and eCommerce datasets ingesting 1M+ data points daily from 10+ sources resulting in insights and forecasting 1M+ trends and context spaces for Fortune 500 clients.
          - Identified new data sources & executed full-cycle development serving 2 clients and long-term business use cases.
          - Built event-driven and containerized data pipelines improving forecast and context-space generation time by 45s.
          - Overhauled monitoring, automation, and validation of BigQuery datasets increasing processing efficiency by 85%.
          - **Technologies used: Python, SQL, GCP (BigQuery, Pub/Sub, Cloud Run/Functions), ETL pipelines, Airflow, Selenium, Git, HTML/CSS/JS**

      - layout: left
        title: University of Maryland
        link: umd.edu
        sub_title: Graduate Assistant (Social-Media Research)
        caption: September 2019 - December 2020
        description: | # this will include new lines to allow paragraphs
          - Channelized online interactions of 30+ companies from 6 social media platforms showing 25% increase in customer satisfaction and positive feedback using sentiment understanding models.
          - Investigated perception towards brand using statistical analysis reflecting 7% positive response.
          - **Technologies used: Python (pandas/scikit-learn/numpy), Selenium, PyTorch, SQL, OpenCV, AWS**

      - layout: left
        title: CERTIFY Health
        link: certify.me
        sub_title: Business Intelligence Engineer
        caption: June 2020 - August 2020
        description: | # this will include new lines to allow paragraphs
          - Designed data synchronization API between Inventory & eCommerce platform fastening order fulfillment by 60%.
          - Organized data management from 10+ sources using ER diagrams & databases improving data retrieval by 80%.
          - Integrated FedEx and UPS APIs in CRM system reducing label generation and shipment times by 3 days.
          - Developed affiliate programs with WordPress and HubSpot for CERTIFY website recording monthly sales of $300,000+.
          - Executed two-week Google Analytics campaign in collaboration with India and China teams leading to 100,000+ website impressions.
          - **Technologies used: Python, Excel, SQL, Tableau, PHP, Azure, Wordpress, Confluence, Lucidchart**

      - layout: left
        title: Indian Institute of Information Technology, Sri City
        link: iiits.ac.in
        sub_title: Undergraduate Student Researcher
        caption: July 2017 - May 2019
        description: | # this will include new lines to allow paragraphs
          - Surveyed 25+ criterion functions used with Convolutional Neural Networks (CNN) for Face Recognition tasks leading to research publication at NCVPRIPG 2019 (http://bit.ly/2Mdi1NG).
          - Conceptualized two deep-learning based Face Recognition methods with Hard-Mining Loss and Parametric-Sigmoid layers each showing 97% plus verification accuracy.
          - Investigated 10+ dataset and architecture advancements in Visual-Question Answering domain using Deep Learning with a conference paper in CVIP 2020 (http://bit.ly/3amuFSs).
          - Published two face recognition methods papers at CVIP 2020 (http://bit.ly/2NHT5Or) and CICT 2019 (http://bit.ly/3oy4IEp) receiving best paper award for Hard-Mining Loss.
          - **Technologies used: Python (pandas/scikit-learn/numpy), PyTorch, Keras, MxNet, OpenCV, Tensorboard**

      - layout: left
        title: CERN (European Organization for Nuclear Research)
        link: home.cern
        sub_title: Software Engineer (Google Summer of Code)
        caption: May 2018 - August 2018
        description: | # this will include new lines to allow paragraphs
          - Spearheaded database migration from MySQL to Elasticsearch for DIRAC open-source project increasing process time efficiency of nuclear experiment data management and analysis by 70%.
          - Revamped database access functions to support Elasticsearch backend overseeing 50% boost in response time.
          - Programmed unit and integration tests producing 25+ tests for execution before production launch.
          - **Technologies used: Python, SQL, ElasticSearch, pytest, Django, Git, Travis CI, Jenkins**

      - layout: left
        title: Physiz
        link: physiz.com
        sub_title: Data Scientist
        caption: August 2017 - September 2017
        description: | # this will include new lines to allow paragraphs
          - Built the leaf-detection pipeline from live-farm image feed using CNNs and PlantCV with 70% detection accuracy.
          - Surveyed 30+ deep-learning mechanisms for geographical nutrient supply analysis summarizing 3 top solutions for research and development.
          - **Technologies used: Python (numpy/pandas/scikit-learn/matplotlib), Keras, CouchDB, OpenCV**

      - layout: left
        title: Bobble AI
        link: bobble.ai
        sub_title: Software QA Engineer
        caption: May 2017 - June 2017
        description: | # this will include new lines to allow paragraphs
          - Diagnosed 10 functional and performance bugs in the Bobble Keyboard application.
          - Programmed test scenarios for 15+ modules of the application covering 20 boundary cases.
          - Overhauled automation tests using Python-based Culebra tool fastening production testing time by 40%.
          - Summarized 5000+ Play Store application reviews with data analytics and visualization and identified 8 customer pain points and preferences.
          - **Technologies used: Java, Python, UI Automator, Espresso, Android Studio, GitHub**

  - title: Education
    layout: list
    content:
      - layout: top-middle
        title: University of Maryland, College Park
        caption: August 2019 - December 2020
        sub_title: M.S. Information Systems (GPA 3.93)

      - layout: top-middle
        title: Indian Institute of Information Technology, Sri City
        caption: August 2015 - May 2019
        sub_title: B.S. (Honors) Computer Science and Engineering (GPA 3.6)

  - title: Skills
    layout: text
    content: | # this will include new lines to allow paragraphs
      - **Languages**: Python, Java, R, HTML, JavaScript

      - **Data**: SQL, NoSQL, CSV/XML/JSON/Avro/Parquet, PyData (NumPy, Pandas, Matplotlib, Jupyter)

      - **Frameworks**: Postgres, BigQuery, ElasticSearch, Hadoop, Spark, Airflow, Scikit-Learn

      - **Machine Learning**: Classification, Regression, Clustering, Forecasting, Decision Trees, Neural Networks

      - **Tools**: Git, Linux, Google Cloud Platform, Docker, Pub/Sub, Selenium, Tableau

  #- title: Projects # Title for the section
  #  layout: list # Type of content section (list/text)
  #  content:
  #    - layout: left
  #      title: Project name
  #      link: Link to project (eg. sproogen.github.io/modern-resume-theme)(optional)
  #      link_text: Link Text
  #      additional_links:
  #        - title:  Github page for project (eg. sproogen/modern-resume-theme)
  #          icon: fab fa-github
  #          url: Link to project (eg. sproogen.github.io/modern-resume-theme)(optional)
  #        - title:  Github page for project (eg. sproogen/modern-resume-theme)
  #          icon: fab fa-github
  #          url: Link to project (eg. sproogen.github.io/modern-resume-theme)(optional)
  #      quote: >
  #        Short overview of the project (optional)
  #      description: | # this will include new lines to allow paragraphs
  #        Description about the work on/with the project
  
  - title: A Little More About Me
    layout: text
    content: | # this will include new lines to allow paragraphs
      Alongside my interests in data science and business intelligence some of my other interests and hobbies are:
        - Liverpool Football Club
        - Telling and listening stories
        - Table Tennis
        - Swimming
        - Trying out new cuisines every week

# More Section
# more_title: A Little More About Me
#more_content: | # this will include new lines to allow paragraphs
#  Alongside my interests in data science and business intelligence some of my other interests and hobbies are:
#   - Liverpool Football Club
#   - Telling and listening stories
#   - Table Tennis
#   - Swimming
#   - Indian and Chinese Food (especially sweets)

# Footer
footer_show_references: true

# Build settings
remote_theme: sproogen/modern-resume-theme

sass:
  sass_dir: _sass
  style: compressed

plugins:
 - jekyll-seo-tag

exclude : [
  "Gemfile",
  "Gemfile.lock",
  "node_modules",
  "vendor/bundle/",
  "vendor/cache/",
  "vendor/gems/",
  "vendor/ruby/",
  "lib/",
  "scripts/",
  "docker-compose.yml",
  ]
